NextBio-Utilities version 0.01
==============================

The README is used to introduce the module and provide instructions on
how to install the module, any machine dependencies it may have (for
example C compilers and installed libraries) and any other information
that should be provided before the module is installed.

A README file is required for CPAN modules since CPAN extracts the
README file from a module distribution so that people browsing the
archive can use it get an idea of the modules uses. It is usually a
good idea to provide version information here so that people can
decide whether fixes for the module are worth downloading.

INSTALLATION

To install this module type the following:

   perl Makefile.PL
   make
   make install

DEPENDENCIES

This module requires these other modules and libraries:

  blah blah blah

COPYRIGHT AND LICENCE

Put the correct copyright and licence information here.

Copyright (C) 2016 by Yongbin Zhuang (happye321@gmail.com)

This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.18.2 or,
at your option, any later version of Perl 5 you may have available.

===================================================================================
usage
===================================================================================
--help 		print this usage
--function	select function to use
--fastq 	fastq file to process
--fasta		fasta file to process
--header	string used to modify fasta header, use with fasta_uniq
--order		up or down used with fasta_sort, default is upward
--length    	read length less than specified value will be removed
--list		Contains list of file names or fasta header
--phy 		.phy file to process
--overhang 	enzyme overhang you want to detect on 5'
--threshold 	floating point value of missing data allowed for samples (default 0.9999)
--depth		minimum depth for a snp to be involved in ploidy analysis

Deamon uage:
#################################  Build-in function ##############################
#get help message 
./NextBio.pl --help

#get uniq fastq file
./NextBio.pl --Function Fastq_uniq --fastq test.fq

#get uniq fasta file and rename header
./NextBio.pl --Function Fasta_uniq --fasta test.fa --header Mine

#sort fasta file based on their length
./NextBio.pl --function Fasta_sort --fasta test.fa --order down

#filter fasta file based on length
./NextBio.pl --function Fasta_length --fasta test.fa --length 10

#extract fasta file by providing a list of header ID (no >)
./NextBio.pl --function Fasta_extract --fasta test.fa --list

#exclude entries from fasta file by providing a list of header ID (no >)
./NextBio.pl --function Fasta_exclude --fasta test.fa --list

#transform fastq to fasta
./NextBio.pl --function Fastq2Fasta --fastq test.fq

#find sequences shared by multiple fasta file, by providing a list of file names, each filename on one line
./NextBio.pl --function Fasta_share --list list.txt

#remove samples contains only Ns and sort the samples based on number of informative bases
./NextBio.pl --function phy_clean --phy ../Pcp.phy --threshold 0.8 >../Pcp_60_cleaned.phy 

#remove sequences not start with expected enzyme cutting overhang in fastq file
./NextBio.pl --function overhang_check --fastq test.q --overhang TTCA

#rename files in current dir, format for list 'currentname	newname', seperate by tab
./NextBio.pl --function file_rename --list list.

#calculate cotig N50
./NextBio.pl --function N50_count --fasta test.fa

#translate DNA into protein with all six reading file_rename
./NextBio.pl --function translate --fasta test.fa


################################# Function requires dependency ####################
****###########################  R, samtools, bcftools, bowtie2####################
#ploidy_plot analysis: single end read
./NextBio.pl --function ploidy --fasta ref.fa --fastq test.fq --depth 30 --header test
#ploidy_plot analysis: paired end reads
./NextBio.pl --function ploidy --fasta ref.fa --fastq test1.fq test2.fq --depth 30 --header test
===================================================================================

